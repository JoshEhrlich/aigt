{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save timestamp: 2021-02-10_09-43-54\n"
     ]
    }
   ],
   "source": [
    "this_notebook_name = \"BreastSegmentationStudy-TF2\"\n",
    "\n",
    "# Update this folder name for your computer\n",
    "\n",
    "local_data_folder = \"/Usersß/Josh Ehrlich/Courses/CISC881/Project/data\"\n",
    "overwrite_existing_data_files = False\n",
    "\n",
    "# All results and output will be archived with this timestamp\n",
    "\n",
    "import datetime\n",
    "save_timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "print(\"Save timestamp: {}\".format(save_timestamp))\n",
    "\n",
    "# Learning parameters\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ultrasound_size = 128\n",
    "num_classes = 2\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "max_learning_rate = 0.02\n",
    "min_learning_rate = 0.000001\n",
    "regularization_rate = 0.0001\n",
    "filter_multiplier = 15\n",
    "class_weights = np.array([0.15, 0.85])\n",
    "learning_rate_decay = (max_learning_rate - min_learning_rate) / num_epochs\n",
    "\n",
    "# Training data augmentation parameters\n",
    "\n",
    "max_shift_factor = 0.12\n",
    "max_rotation_angle = 10\n",
    "max_zoom_factor = 1.1\n",
    "min_zoom_factor = 0.8\n",
    "\n",
    "# Evaluation parameters\n",
    "\n",
    "acceptable_margin_mm = 1.0\n",
    "mm_per_pixel = 1.0\n",
    "\n",
    "roc_thresholds = [0.9, 0.8, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1,\n",
    "                  0.08, 0.06, 0.04, 0.02, 0.01,\n",
    "                  0.008, 0.006, 0.004, 0.002, 0.001]\n",
    "\n",
    "'''\n",
    "Provide NxM numpy array to schedule cross validation\n",
    "N rounds of validation will be performed, leaving out M patients in each for validation data\n",
    "All values should be valid patient IDs, or negative. Negative values are ignored.\n",
    "\n",
    "Example 1: a leave-one-out cross validation with 3 patients would look like this:\n",
    "validation_schedule_patient = np.array([[0],[1],[2]])\n",
    "\n",
    "Example 2: a leave-two-out cross validation on 10 patients would look like this:\n",
    "validation_schedule_patient = np.array([[0,1],[2,3],[4,5],[6,7],[8,9]])\n",
    "\n",
    "Example 3: leave-one-out cross validation with 3 patients, then training on all available data (no validation):\n",
    "validation_schedule_patient = np.array([[0],[1],[2],[-1]])\n",
    "'''\n",
    "validation_schedule_patient = np.array([ [19,22,29,32], [20,23,27,30]])\n",
    "                                        #to complete next time:[0,1,2,3], [7,11,13,18], [9,14,21,31]\n",
    "\n",
    "# Uncomment for faster debugging\n",
    "\n",
    "roc_thresholds = [0.8, 0.6, 0.4, 0.2, 0.1, 0.01, 0.001]\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import sample\n",
    "from pathlib import Path\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import diskcache\n",
    "import girder_client\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import ultrasound_batch_generator as generator\n",
    "import evaluation_metrics\n",
    "\n",
    "from girder_apikey import girder_apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import aigt modules\n",
    "\n",
    "import sys\n",
    "parent_folder = os.path.dirname(os.path.abspath(os.curdir))\n",
    "sys.path.append(parent_folder)\n",
    "\n",
    "import Models.segmentation_unet as unet\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating standard folders to save data and logs\n",
    "\n",
    "data_arrays_fullpath, notebooks_save_fullpath, results_save_fullpath, models_save_fullpath, val_data_fullpath =\\\n",
    "    utils.create_standard_project_folders(local_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 0 has 379 ultrasounds and 379 segmentations\n",
      "Patient 1 has 292 ultrasounds and 292 segmentations\n",
      "Patient 2 has 426 ultrasounds and 426 segmentations\n",
      "Patient 3 has 418 ultrasounds and 418 segmentations\n",
      "Patient 4 has 442 ultrasounds and 442 segmentations\n",
      "Patient 5 has 224 ultrasounds and 224 segmentations\n",
      "Patient 6 has 272 ultrasounds and 272 segmentations\n",
      "Patient 7 has 288 ultrasounds and 288 segmentations\n",
      "Patient 8 has 175 ultrasounds and 175 segmentations\n",
      "Patient 9 has 113 ultrasounds and 113 segmentations\n",
      "Patient 10 has 237 ultrasounds and 237 segmentations\n",
      "Patient 11 has 180 ultrasounds and 180 segmentations\n",
      "Patient 12 has 5 ultrasounds and 5 segmentations\n",
      "Patient 13 has 402 ultrasounds and 402 segmentations\n",
      "Patient 14 has 295 ultrasounds and 295 segmentations\n",
      "Patient 15 has 331 ultrasounds and 331 segmentations\n",
      "Patient 16 has 145 ultrasounds and 145 segmentations\n",
      "Patient 17 has 253 ultrasounds and 253 segmentations\n",
      "Patient 18 has 158 ultrasounds and 158 segmentations\n",
      "Patient 19 has 187 ultrasounds and 187 segmentations\n",
      "Patient 20 has 135 ultrasounds and 135 segmentations\n",
      "Patient 21 has 107 ultrasounds and 107 segmentations\n",
      "Patient 22 has 238 ultrasounds and 238 segmentations\n",
      "Patient 23 has 226 ultrasounds and 226 segmentations\n",
      "Patient 24 has 162 ultrasounds and 162 segmentations\n",
      "Patient 25 has 124 ultrasounds and 124 segmentations\n",
      "Patient 26 has 209 ultrasounds and 209 segmentations\n",
      "Patient 27 has 123 ultrasounds and 123 segmentations\n",
      "Patient 28 has 181 ultrasounds and 181 segmentations\n",
      "Patient 29 has 134 ultrasounds and 134 segmentations\n",
      "Patient 30 has 145 ultrasounds and 145 segmentations\n",
      "Patient 31 has 133 ultrasounds and 133 segmentations\n",
      "Patient 32 has 179 ultrasounds and 179 segmentations\n"
     ]
    }
   ],
   "source": [
    "# Fetching Girder data\n",
    "\n",
    "girder_url = \"https://pocus.cs.queensu.ca/api/v1\"\n",
    "data_csv_file = \"BreastGirder.csv\"\n",
    "girder_key = girder_apikey\n",
    "\n",
    "ultrasound_arrays_by_patients, segmentation_arrays_by_patients =\\\n",
    "    utils.load_girder_data(data_csv_file, data_arrays_fullpath, girder_url, girder_key)\n",
    "    \n",
    "n_patients = len(ultrasound_arrays_by_patients)\n",
    "\n",
    "for i in range(n_patients):\n",
    "    print(\"Patient {} has {} ultrasounds and {} segmentations\".format(\n",
    "        i, ultrasound_arrays_by_patients[i].shape[0], segmentation_arrays_by_patients[i].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning 2 rounds of validation\n",
      "Validation on patients [19 22 29 32] in round 0\n",
      "Validation on patients [20 23 27 30] in round 1\n"
     ]
    }
   ],
   "source": [
    "# Prepare validation rounds\n",
    "\n",
    "if np.max(np.max(validation_schedule_patient)) > (n_patients - 1):\n",
    "    raise Exception(\"Patient ID cannot be greater than {}\".format(n_patients - 1))\n",
    "\n",
    "num_validation_rounds = len(validation_schedule_patient)\n",
    "print(\"Planning {} rounds of validation\".format(num_validation_rounds))\n",
    "for i in range(num_validation_rounds):\n",
    "    print(\"Validation on patients {} in round {}\".format(validation_schedule_patient[i], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp for saved files: 2021-02-10_09-43-54\n",
      "\n",
      "Training parameters\n",
      "Number of epochs:    200\n",
      "Step size maximum:   0.02\n",
      "Step size decay:     9.9995e-05\n",
      "Batch size:          64\n",
      "Regularization rate: 0.0001\n",
      "\n",
      "Saving validation predictions in: /Usersß/Josh Ehrlich/Courses/CISC881/Project/data\\PredictionsValidation\n",
      "Saving models in:                 /Usersß/Josh Ehrlich/Courses/CISC881/Project/data\\SavedModels\n",
      "\n",
      "*** Leave-one-out round # 0\n",
      "    Training on 6580 images, validating on 738 images...\n",
      "[<tf.Tensor 'batch_normalization_7/cond/Identity:0' shape=(None, 16, 16, 128) dtype=float32>]\n",
      "[<tf.Tensor 'batch_normalization_5/cond/Identity:0' shape=(None, 32, 32, 64) dtype=float32>]\n",
      "[<tf.Tensor 'batch_normalization_3/cond/Identity:0' shape=(None, 64, 64, 32) dtype=float32>]\n",
      "[<tf.Tensor 'batch_normalization_1/cond/Identity:0' shape=(None, 128, 128, 16) dtype=float32>]\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 16) 160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 16) 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d (SpatialDropo (None, 128, 128, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 16) 2320        spatial_dropout2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 32)   4640        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 32)   128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_1 (SpatialDro (None, 64, 64, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 32)   9248        spatial_dropout2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_2 (SpatialDro (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   36928       spatial_dropout2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_3 (SpatialDro (None, 16, 16, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 128)  147584      spatial_dropout2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 128)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 256)    295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 256)    1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_4 (SpatialDro (None, 8, 8, 256)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 256)    590080      spatial_dropout2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 256)    1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 16, 16, 128)  131200      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 128)  16512       conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 128)  16512       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 16, 16, 128)  0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16, 16, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 1)    129         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16, 16, 1)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 16, 16, 128)  0           conv2d_10[0][0]                  \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 16, 256)  0           conv2d_transpose[0][0]           \n",
      "                                                                 multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 128)  131200      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 128)  65664       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 128)  512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 64)   32832       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 64)   4160        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 64)   4160        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 64)   0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 1)    65          activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 1)    0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 32, 32, 64)   0           conv2d_15[0][0]                  \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 128)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 64)   32832       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 64)   16448       batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 32)   8224        batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 32)   1056        conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 32)   1056        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 32)   0           conv2d_20[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 32)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 1)    33          activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 1)    0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 64, 64, 32)   0           conv2d_20[0][0]                  \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 64)   0           conv2d_transpose_2[0][0]         \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 32)   8224        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 32)   128         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 32)   4128        batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 32)   128         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 16) 2064        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 128, 128, 16) 272         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 128, 128, 16) 272         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 128, 16) 0           conv2d_25[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128, 128, 16) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 128, 128, 1)  17          activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 128, 128, 1)  0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 128, 128, 16) 0           conv2d_25[0][0]                  \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 32) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 128, 128, 16) 2064        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 16) 64          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 128, 128, 16) 1040        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 128, 128, 16) 64          conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 128, 32) 0           batch_normalization_17[0][0]     \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 128, 128, 16) 2064        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 128, 128, 16) 64          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 128, 128, 16) 1040        batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 128, 128, 16) 64          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 128, 128, 2)  130         batch_normalization_19[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,667,894\n",
      "Trainable params: 1,664,886\n",
      "Non-trainable params: 3,008\n",
      "__________________________________________________________________________________________________\n",
      "TRAINING LOG <ultrasound_batch_generator.UltrasoundSegmentationBatchGenerator object at 0x000001B2BA4D5AC0>\n",
      "WARNING:tensorflow:From <ipython-input-7-8c692a80e842>:175: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training time: 1 day, 3:10:59.565894\n",
      "(738, 128, 128, 1)\n",
      "\n",
      "Total round time:  1 day, 3:11:10.801040\n",
      "\n",
      "\n",
      "*** Leave-one-out round # 1\n",
      "    Training on 6689 images, validating on 629 images...\n",
      "[<tf.Tensor 'batch_normalization_27/cond/Identity:0' shape=(None, 16, 16, 128) dtype=float32>]\n",
      "[<tf.Tensor 'batch_normalization_25/cond/Identity:0' shape=(None, 32, 32, 64) dtype=float32>]\n",
      "[<tf.Tensor 'batch_normalization_23/cond/Identity:0' shape=(None, 64, 64, 32) dtype=float32>]\n",
      "[<tf.Tensor 'batch_normalization_21/cond/Identity:0' shape=(None, 128, 128, 16) dtype=float32>]\n",
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 128, 128, 16) 160         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 128, 128, 16) 64          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_5 (SpatialDro (None, 128, 128, 16) 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 128, 128, 16) 2320        spatial_dropout2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 128, 128, 16) 64          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 16)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 64, 64, 32)   4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 64, 64, 32)   128         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_6 (SpatialDro (None, 64, 64, 32)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 64, 64, 32)   9248        spatial_dropout2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 64, 32)   128         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 32)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 64)   18496       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 64)   256         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_7 (SpatialDro (None, 32, 32, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 64)   36928       spatial_dropout2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 64)   256         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 128)  73856       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 128)  512         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_8 (SpatialDro (None, 16, 16, 128)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 128)  147584      spatial_dropout2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 128)  512         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 128)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 8, 8, 256)    295168      max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 256)    1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_9 (SpatialDro (None, 8, 8, 256)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 8, 256)    590080      spatial_dropout2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 256)    1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 16, 16, 128)  131200      batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 128)  16512       conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 128)  16512       batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 128)  0           conv2d_43[0][0]                  \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 128)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 1)    129         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 1)    0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 16, 16, 128)  0           conv2d_43[0][0]                  \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 16, 256)  0           conv2d_transpose_4[0][0]         \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 128)  131200      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 128)  512         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 128)  65664       batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 128)  512         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 32, 32, 64)   32832       batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 32, 32, 64)   4160        conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 32, 32, 64)   4160        batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 64)   0           conv2d_48[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 64)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 32, 32, 1)    65          activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 1)    0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 32, 32, 64)   0           conv2d_48[0][0]                  \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 128)  0           conv2d_transpose_5[0][0]         \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 32, 32, 64)   32832       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 64)   256         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 32, 32, 64)   16448       batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 32, 64)   256         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 64, 64, 32)   8224        batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 64, 64, 32)   1056        conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 64, 64, 32)   1056        batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 64, 32)   0           conv2d_53[0][0]                  \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 32)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 64, 64, 1)    33          activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 1)    0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 64, 64, 32)   0           conv2d_53[0][0]                  \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 64)   0           conv2d_transpose_6[0][0]         \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 64, 64, 32)   8224        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 64, 64, 32)   128         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 64, 64, 32)   4128        batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 64, 64, 32)   128         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 128, 128, 16) 2064        batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 128, 128, 16) 272         conv2d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 128, 128, 16) 272         batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 128, 128, 16) 0           conv2d_58[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 128, 16) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 128, 128, 1)  17          activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 128, 1)  0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 128, 128, 16) 0           conv2d_58[0][0]                  \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 128, 128, 32) 0           conv2d_transpose_7[0][0]         \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 128, 128, 16) 2064        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 128, 128, 16) 64          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 128, 128, 16) 1040        batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 128, 128, 16) 64          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 128, 128, 32) 0           batch_normalization_37[0][0]     \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 128, 128, 16) 2064        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 128, 128, 16) 64          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 128, 128, 16) 1040        batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 128, 128, 16) 64          conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 128, 128, 2)  130         batch_normalization_39[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,667,894\n",
      "Trainable params: 1,664,886\n",
      "Non-trainable params: 3,008\n",
      "__________________________________________________________________________________________________\n",
      "TRAINING LOG <ultrasound_batch_generator.UltrasoundSegmentationBatchGenerator object at 0x000001B2BD643640>\n"
     ]
    }
   ],
   "source": [
    "# Print training parameters, to archive them together with the notebook output.\n",
    "\n",
    "time_sequence_start = datetime.datetime.now()\n",
    "\n",
    "print(\"Timestamp for saved files: {}\".format(save_timestamp))\n",
    "print(\"\\nTraining parameters\")\n",
    "print(\"Number of epochs:    {}\".format(num_epochs))\n",
    "print(\"Step size maximum:   {}\".format(max_learning_rate))\n",
    "print(\"Step size decay:     {}\".format(learning_rate_decay))\n",
    "print(\"Batch size:          {}\".format(batch_size))\n",
    "print(\"Regularization rate: {}\".format(regularization_rate))\n",
    "print(\"\")\n",
    "print(\"Saving validation predictions in: {}\".format(val_data_fullpath))\n",
    "print(\"Saving models in:                 {}\".format(models_save_fullpath))\n",
    "\n",
    "# ROC data will be saved in these containers\n",
    "\n",
    "val_best_metrics    = dict()\n",
    "val_fuzzy_metrics   = dict()\n",
    "val_aurocs          = np.zeros(num_validation_rounds)\n",
    "val_best_thresholds = np.zeros(num_validation_rounds)\n",
    "\n",
    "# Perform validation rounds\n",
    "\n",
    "for val_round_index in range(num_validation_rounds):\n",
    "    \n",
    "    # Prepare data arrays\n",
    "    \n",
    "    train_ultrasound_data = np.zeros(\n",
    "        [0,\n",
    "         ultrasound_arrays_by_patients[0].shape[1],\n",
    "         ultrasound_arrays_by_patients[0].shape[2],\n",
    "         ultrasound_arrays_by_patients[0].shape[3]])\n",
    "    \n",
    "    train_segmentation_data = np.zeros(\n",
    "        [0,\n",
    "         segmentation_arrays_by_patients[0].shape[1],\n",
    "         segmentation_arrays_by_patients[0].shape[2],\n",
    "         segmentation_arrays_by_patients[0].shape[3]])\n",
    "    \n",
    "    val_ultrasound_data = np.zeros(\n",
    "        [0,\n",
    "         ultrasound_arrays_by_patients[0].shape[1],\n",
    "         ultrasound_arrays_by_patients[0].shape[2],\n",
    "         ultrasound_arrays_by_patients[0].shape[3]])\n",
    "    \n",
    "    val_segmentation_data = np.zeros(\n",
    "        [0,\n",
    "         segmentation_arrays_by_patients[0].shape[1],\n",
    "         segmentation_arrays_by_patients[0].shape[2],\n",
    "         segmentation_arrays_by_patients[0].shape[3]])\n",
    "    \n",
    "    for patient_index in range(n_patients):\n",
    "        if patient_index not in validation_schedule_patient[val_round_index]:\n",
    "            train_ultrasound_data = np.concatenate((train_ultrasound_data,\n",
    "                                                    ultrasound_arrays_by_patients[patient_index]))\n",
    "            train_segmentation_data = np.concatenate((train_segmentation_data,\n",
    "                                                      segmentation_arrays_by_patients[patient_index]))\n",
    "        else:\n",
    "            val_ultrasound_data = np.concatenate((val_ultrasound_data,\n",
    "                                                 ultrasound_arrays_by_patients[patient_index]))\n",
    "            val_segmentation_data = np.concatenate((val_segmentation_data,\n",
    "                                                   segmentation_arrays_by_patients[patient_index]))\n",
    "    \n",
    "    n_train = train_ultrasound_data.shape[0]\n",
    "    n_val = val_ultrasound_data.shape[0]\n",
    "    \n",
    "    print(\"\\n*** Leave-one-out round # {}\".format(val_round_index))\n",
    "    print(\"    Training on {} images, validating on {} images...\".format(n_train, n_val))\n",
    "    \n",
    "    val_segmentation_data_onehot = tf.keras.utils.to_categorical(val_segmentation_data, num_classes)\n",
    "    \n",
    "    # Create and train model\n",
    "    \n",
    "    model = unet.segmentation_unet(ultrasound_size, num_classes, filter_multiplier, regularization_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=max_learning_rate, decay=learning_rate_decay),\n",
    "        loss=unet.weighted_categorical_crossentropy(class_weights),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    '''\n",
    "    #----------------------------------------------------------------------------\n",
    "    import os\n",
    "    import sys\n",
    "    import datetime\n",
    "    from random import sample\n",
    "    from pathlib import Path\n",
    "    import girder_client\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "\n",
    "    from Spine.ultrasound_batch_generator import train_preprocess, train_preprocess_with_maps, generate_weight_maps\n",
    "    from Spine import evaluation_metrics\n",
    "\n",
    "    from Spine.models import (\n",
    "        new_unet,\n",
    "        weighted_categorical_crossentropy,\n",
    "        weighted_categorical_crossentropy_with_maps,\n",
    "    )\n",
    "    import utils\n",
    "\n",
    "\n",
    "    batch_size=128, \n",
    "    num_epochs=100, \n",
    "    sagittal_only=False, \n",
    "    num_frames=1, \n",
    "    with_maps=False, \n",
    "    learning_rate=0.002,\n",
    "    lr_decay=False,\n",
    "    dropout=0.0,\n",
    "    use_attention=True,\n",
    "    num_layers=5,\n",
    "    filters=16,\n",
    "    use_batch_norm=True,\n",
    "    load_from_save=False,\n",
    "\n",
    "    ultrasound_size = 128\n",
    "    batch_size = 128\n",
    "    num_classes = 2\n",
    "    min_learning_rate = 0.00001\n",
    "    class_weights = np.array([0.1, 0.9])\n",
    "    learning_rate_decay = (0.002-0.00001) / 100\n",
    "    num_epochs = 100\n",
    "\n",
    "    model = new_unet(\n",
    "                input_size = ultrasound_size,\n",
    "                num_classes=num_classes,\n",
    "                num_channels=num_frames,\n",
    "                use_batch_norm=use_batch_norm,\n",
    "                upsample_mode=\"deconv\",  # 'deconv' or 'simple'\n",
    "                dropout=dropout,\n",
    "                dropout_type=\"spatial\",\n",
    "                use_attention=use_attention,\n",
    "                filters=filters,\n",
    "                num_layers=num_layers,\n",
    "                output_activation=\"softmax\",\n",
    "            )\n",
    "\n",
    "    learning_rate = 0.002\n",
    "    loss_func = weighted_categorical_crossentropy(class_weights)\n",
    "    \n",
    "    preprocess_func = train_preprocess\n",
    "    print(learning_rate, learning_rate_decay)\n",
    "    model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(\n",
    "                    lr=learning_rate, decay=learning_rate_decay\n",
    "                ),\n",
    "                loss=loss_func,\n",
    "                metrics=[\"accuracy\", evaluation_metrics.jaccard_coef, evaluation_metrics.dice_coef],\n",
    "            )\n",
    "\n",
    "#-----------------------------------------------------\n",
    "    '''\n",
    "    \n",
    "    model.summary() #prints the structure of the neural network. If you change the unet,\n",
    "    #print this so yuo can see it.\n",
    "\n",
    "    training_generator = generator.UltrasoundSegmentationBatchGenerator(\n",
    "        train_ultrasound_data,\n",
    "        train_segmentation_data[:, :, :, 0],\n",
    "        batch_size,\n",
    "        (ultrasound_size, ultrasound_size),\n",
    "        max_shift_factor=max_shift_factor,\n",
    "        min_zoom_factor=min_zoom_factor,\n",
    "        max_zoom_factor=max_zoom_factor,\n",
    "        max_rotation_angle=max_rotation_angle\n",
    "    )\n",
    "        \n",
    "    training_time_start = datetime.datetime.now()\n",
    "    print(\"TRAINING LOG\",training_generator)\n",
    "    if n_val > 0:\n",
    "        training_log = model.fit_generator(\n",
    "            training_generator,\n",
    "            validation_data=(val_ultrasound_data, val_segmentation_data_onehot),\n",
    "            epochs=num_epochs,\n",
    "            verbose=0)\n",
    "    else:\n",
    "        training_log = model.fit_generator(training_generator, epochs=num_epochs, verbose=0)\n",
    "    \n",
    "    training_time_stop = datetime.datetime.now()\n",
    "    \n",
    "    # Pring training log\n",
    "    \n",
    "    print(\"  Training time: {}\".format(training_time_stop-training_time_start))\n",
    "    \n",
    "    # Plot training loss and metrics\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].plot(training_log.history['loss'], 'bo--')\n",
    "    if n_val > 0:\n",
    "        axes[0].plot(training_log.history['val_loss'], 'ro-')\n",
    "    axes[0].set(xlabel='Epochs (n)', ylabel='Loss')\n",
    "    if n_val > 0:\n",
    "        axes[0].legend(['Training loss', 'Validation loss'])\n",
    "    \n",
    "    axes[1].plot(training_log.history['accuracy'], 'bo--')\n",
    "    if n_val > 0:\n",
    "        axes[1].plot(training_log.history['val_accuracy'], 'ro-')\n",
    "    axes[1].set(xlabel='Epochs (n)', ylabel='Accuracy')\n",
    "    if n_val > 0:\n",
    "        axes[1].legend(['Training accuracy', 'Validation accuracy'])\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Archive trained model with unique filename based on notebook name and timestamp\n",
    "    model_file_name = this_notebook_name + \"_model-\" + str(val_round_index) + \"_\" + save_timestamp + \".h5\"\n",
    "    model_fullname = os.path.join(models_save_fullpath, model_file_name)\n",
    "    model.save(model_fullname)\n",
    "\n",
    "    # Predict on validation data\n",
    "    \n",
    "    if n_val > 0:\n",
    "        print(val_ultrasound_data.shape)\n",
    "        y_pred_val  = model.predict(val_ultrasound_data)\n",
    "\n",
    "        # Saving predictions for further evaluation\n",
    "\n",
    "        val_prediction_filename = save_timestamp + \"_prediction_\" + str(val_round_index) + \".npy\"\n",
    "        val_prediction_fullname = os.path.join(val_data_fullpath, val_prediction_filename)\n",
    "        np.save(val_prediction_fullname, y_pred_val)\n",
    "        \n",
    "        # Validation results\n",
    "\n",
    "        vali_metrics_dicts, vali_best_threshold_index, vali_area = evaluation_metrics.compute_roc(\n",
    "            roc_thresholds, y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "\n",
    "        val_fuzzy_metrics[val_round_index] = evaluation_metrics.compute_evaluation_metrics(\n",
    "            y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "\n",
    "        val_best_metrics[val_round_index]    = vali_metrics_dicts[vali_best_threshold_index]\n",
    "        val_aurocs[val_round_index]          = vali_area\n",
    "        val_best_thresholds[val_round_index] = roc_thresholds[vali_best_threshold_index]\n",
    "    \n",
    "    # Printing total time of this validation round\n",
    "    \n",
    "    print(\"\\nTotal round time:  {}\".format(datetime.datetime.now() - training_time_start))\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "time_sequence_stop = datetime.datetime.now()\n",
    "\n",
    "print(\"\\nTotal training time:   {}\".format(time_sequence_stop - time_sequence_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange results in tables\n",
    "\n",
    "metric_labels = [\n",
    "    \"AUROC\",\n",
    "    \"best thresh\",\n",
    "    \"best TP\",\n",
    "    \"best FP\",\n",
    "    \"best recall\",\n",
    "    \"best precis\",\n",
    "    \"fuzzy recall\",\n",
    "    \"fuzzy precis\",\n",
    "    \"fuzzy Fscore\"\n",
    "]\n",
    "\n",
    "results_labels = []\n",
    "  \n",
    "for label in metric_labels:\n",
    "    results_labels.append(\"Vali \" + label)\n",
    "\n",
    "results_df = pd.DataFrame(columns = results_labels)\n",
    "\n",
    "for i in range(num_validation_rounds):\n",
    "    if i in val_best_metrics.keys():\n",
    "        results_df.loc[i] = [\n",
    "            val_aurocs[i],\n",
    "            val_best_thresholds[i],\n",
    "            val_best_metrics[i][evaluation_metrics.TRUE_POSITIVE_RATE],\n",
    "            val_best_metrics[i][evaluation_metrics.FALSE_POSITIVE_RATE],\n",
    "            val_best_metrics[i][evaluation_metrics.RECALL],\n",
    "            val_best_metrics[i][evaluation_metrics.PRECISION],\n",
    "            val_fuzzy_metrics[i][evaluation_metrics.RECALL],\n",
    "            val_fuzzy_metrics[i][evaluation_metrics.PRECISION],\n",
    "            val_fuzzy_metrics[i][evaluation_metrics.FSCORE]\n",
    "        ]\n",
    "\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\nAverages\")\n",
    "\n",
    "results_means_df = results_df.mean()\n",
    "display(results_means_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the last ROC curve for visual verification that we catch the optimal point\n",
    "\n",
    "n = len(roc_thresholds)\n",
    "\n",
    "roc_x = np.zeros(n)\n",
    "roc_y = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "    roc_x[i] = vali_metrics_dicts[i][evaluation_metrics.FALSE_POSITIVE_RATE]\n",
    "    roc_y[i] = vali_metrics_dicts[i][evaluation_metrics.SENSITIVITY]\n",
    "    # print(\"Threshold = {0:4.2f}  False pos rate = {1:4.2f}  Sensitivity = {2:4.2f}\"\n",
    "    #       .format(roc_thresholds[i], roc_x[i], roc_y[i]))\n",
    "\n",
    "    \n",
    "plt.figure()\n",
    "plt.ylim(-0.01, 1.01)\n",
    "plt.xlim(-0.01, 1.01)\n",
    "plt.plot(roc_x, roc_y, color='darkred', lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results table\n",
    "\n",
    "csv_filename = this_notebook_name + \"_\" + save_timestamp + \".csv\"\n",
    "csv_fullname = os.path.join(results_save_fullpath, csv_filename)\n",
    "results_df.to_csv(csv_fullname)\n",
    "\n",
    "print(\"Results saved to: {}\".format(csv_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display sample results\n",
    "\n",
    "# determine the available ultrasounds in the last round of validation\n",
    "last_round = validation_schedule_patient[-1]\n",
    "print(val_ultrasound_data.shape)\n",
    "prev_vali = 0\n",
    "\n",
    "#20: [63, 94, 72, 121, 130, 2, 64, 111, 26, 46, 12, 67, 132, 49, 61, 90, 65, 106, 14, 100]\n",
    "#23: [347, 185, 215, 228, 345, 176, 186, 335, 301, 237, 316, 288, 181, 354, 331, 261, 194, 225, 205, 153]\n",
    "#27: [364, 459, 405, 464, 426, 397, 483, 416, 430, 392, 447, 401, 423, 409, 378, 458, 422, 445, 451, 379]\n",
    "#30: [494, 488, 571, 626, 568, 529, 582, 486, 484, 533, 485, 574, 507, 516, 493, 499, 549, 561, 625, 523]\n",
    "count = 0\n",
    "patientNumber = [20, 23, 27, 30]\n",
    "sample_indices = [[63, 94, 72, 121, 130, 2, 64, 111, 26, 46, 12, 67, 132, 49, 61, 90, 65, 106, 14, 100], [347, 185, 215, 228, 345, 176, 186, 335, 301, 237, 316, 288, 181, 354, 331, 261, 194, 225, 205, 153], [364, 459, 405, 464, 426, 397, 483, 416, 430, 392, 447, 401, 423, 409, 378, 458, 422, 445, 451, 379], [494, 488, 571, 626, 568, 529, 582, 486, 484, 533, 485, 574, 507, 516, 493, 499, 549, 561, 625, 523]]\n",
    "for j in range(len(last_round)):\n",
    "    \n",
    "    num_vali =  prev_vali + ultrasound_arrays_by_patients[last_round[j]].shape[0]\n",
    "    num_show = 20\n",
    "    if num_vali < num_show:\n",
    "        num_show = 0\n",
    "    num_col = 4\n",
    "\n",
    "    indices = [i for i in range(prev_vali, num_vali)]\n",
    "    #sample_indices = sample(indices, num_show)\n",
    "    print(\"Showing image slices for patient\", patientNumber[count], \":\", sample_indices[count])\n",
    "    #sample_indices = [prev_vali]\n",
    "    \n",
    "    # update\n",
    "    prev_vali = num_vali\n",
    "    threshold = 0.5\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, num_show*5))\n",
    "    for i in range(num_show):\n",
    "        a0 = fig.add_subplot(num_show, num_col, i*num_col+1)\n",
    "        img0 = a0.imshow(np.flipud(val_ultrasound_data[sample_indices[count][i], :, :, 0].astype(np.float32)))\n",
    "        a0.set_title(\"Patient #{} - Ultrasound #{}\".format(last_round[j], sample_indices[count][i]))\n",
    "        a1 = fig.add_subplot(num_show, num_col, i*num_col+2)\n",
    "        img1 = a1.imshow(np.flipud(val_segmentation_data_onehot[sample_indices[count][i], :, :, 1]), vmin=0.0, vmax=1.0)\n",
    "        a1.set_title(\"Segmentation #{}\".format(sample_indices[count][i]))\n",
    "        c = fig.colorbar(img1, fraction=0.046, pad=0.04)\n",
    "        a2 = fig.add_subplot(num_show, num_col, i*num_col+3)\n",
    "        img2 = a2.imshow(np.flipud(y_pred_val[sample_indices[count][i], :, :, 1]), vmin=0.0, vmax=1.0)\n",
    "        a2.set_title(\"Prediction #{}\".format(sample_indices[count][i]))\n",
    "        c = fig.colorbar(img2, fraction=0.046, pad=0.04)\n",
    "        a3 = fig.add_subplot(num_show, num_col, i*num_col+4)\n",
    "        img3 = a3.imshow((np.flipud(y_pred_val[sample_indices[count][i], :, :, 1]) > threshold), vmin=0.0, vmax=1.0)\n",
    "        c = fig.colorbar(img3, fraction=0.046, pad=0.04)\n",
    "        a3.set_title(\"Thresholded #{}\".format(sample_indices[count][i]))\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save notebook so all output is archived by the next cell\n",
    "\n",
    "from IPython.display import Javascript\n",
    "script = '''\n",
    "require([\"base/js/namespace\"],function(Jupyter) {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "});\n",
    "'''\n",
    "Javascript(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Arrange results in tables\n",
    "\n",
    "metric_labels = [\n",
    "    'overall accuracy',\n",
    "    'sensitivity-wrong',\n",
    "    \"AUROC\",\n",
    "    \"best thresh\",\n",
    "    \"best TP\",\n",
    "    \"best FP\",\n",
    "    \"best recall\",\n",
    "    \"best precis\",\n",
    "    \"fuzzy recall\",\n",
    "    \"fuzzy precis\",\n",
    "    \"fuzzy Fscore\"\n",
    "]\n",
    "\n",
    "results_labels = []\n",
    "  \n",
    "for label in metric_labels:\n",
    "    results_labels.append(\"Vali \" + label)\n",
    "\n",
    "results_df = pd.DataFrame(columns = results_labels)\n",
    "\n",
    "for i in range(num_validation_rounds):\n",
    "    if i in val_best_metrics.keys():\n",
    "        results_df.loc[i] = [\n",
    "            val_best_metrics[i][evaluation_metrics.ACCURACY]*100,\n",
    "            (val_best_metrics[i][evaluation_metrics.TRUE_POSITIVE_RATE])/(val_best_metrics[i][evaluation_metrics.TRUE_POSITIVE_RATE] + (1-val_best_metrics[i][evaluation_metrics.TRUE_POSITIVE_RATE])),\n",
    "            val_aurocs[i],\n",
    "            val_best_thresholds[i],\n",
    "            val_best_metrics[i][evaluation_metrics.TRUE_POSITIVE_RATE],\n",
    "            val_best_metrics[i][evaluation_metrics.FALSE_POSITIVE_RATE],\n",
    "            val_best_metrics[i][evaluation_metrics.RECALL],\n",
    "            val_best_metrics[i][evaluation_metrics.PRECISION],\n",
    "            val_fuzzy_metrics[i][evaluation_metrics.RECALL],\n",
    "            val_fuzzy_metrics[i][evaluation_metrics.PRECISION],\n",
    "            val_fuzzy_metrics[i][evaluation_metrics.FSCORE]\n",
    "        ]\n",
    "\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\nAverages\")\n",
    "\n",
    "results_means_df = results_df.mean()\n",
    "display(results_means_df)\n",
    "'''\n",
    "\n",
    "# Arrange results in tables\n",
    "\n",
    "#metric_labels = [\n",
    "#    \"Acc\",\n",
    "#    \"AUROC\",\n",
    "#    \"best thresh\",\n",
    "#    \"best TP\",\n",
    "#    \"best FP\",\n",
    "#    \"best recall\",\n",
    "#    \"best precis\",\n",
    "#    \"best dice\",\n",
    "#    \"fuzzy recall\",\n",
    "#    \"fuzzy precis\",\n",
    "#    \"fuzzy Fscore\"\n",
    "#]\n",
    "\n",
    "metric_labels = [\n",
    "    \"Overall Acc\",\n",
    "    \"Image Classification Acc\",\n",
    "    \"Img Classification TP\",\n",
    "    \"Img Classification FP\",\n",
    "    \"Img Classification FN\",\n",
    "    \"Img Classification TN\",\n",
    "    \"Img Classification Sensitivity (TP/(TP+FN))\",\n",
    "    \"Img Classification Specificity (TN/(TN+FP))\",\n",
    "    \"Img Classification Precision (TP/(TP+FP))\",\n",
    "    \"Avg Center Distance\",\n",
    "    \"Avg Prediction Overlap\",\n",
    "    \"Avg Missed Prediction\",\n",
    "    \"Dice\"    \n",
    "]\n",
    "results_labels = []\n",
    "\n",
    "for label in metric_labels:\n",
    "    results_labels.append(\"Test \" + label)\n",
    "\n",
    "    \n",
    "results_df = pd.DataFrame(columns = results_labels)\n",
    "\n",
    "num_models = num_validation_rounds\n",
    "test_best_metrics = val_best_metrics\n",
    "\n",
    "for i in range(num_models):\n",
    "    results_df.loc[i] = [\n",
    "        test_best_metrics[i][evaluation_metrics.ACCURACY]*100,\n",
    "        img_ACCs[i]*100,\n",
    "        img_TPs[i],\n",
    "        img_FPs[i],\n",
    "        img_FNs[i],\n",
    "        img_TNs[i],\n",
    "        img_TPs[i]/(max(1,img_TPs[i]+img_FNs[i]))*100,\n",
    "        img_TNs[i]/(max(1,img_TNs[i]+img_FPs[i]))*100,\n",
    "        img_TPs[i]/(max(1,img_TPs[i]+img_FPs[i]))*100,\n",
    "        totDistanceErrs[i],\n",
    "        totSeg[i]*100,\n",
    "        totMissed[i]*100,\n",
    "        #test_aurocs[i],\n",
    "        #test_best_thresholds[i],\n",
    "        #test_best_metrics[i][evaluation_metrics.TRUE_POSITIVE_RATE],\n",
    "        #test_best_metrics[i][evaluation_metrics.FALSE_POSITIVE_RATE],\n",
    "        #test_best_metrics[i][evaluation_metrics.RECALL],\n",
    "        #test_best_metrics[i][evaluation_metrics.PRECISION],\n",
    "        test_best_metrics[i][evaluation_metrics.DICE]*100,\n",
    "        #test_fuzzy_metrics[i][evaluation_metrics.RECALL],\n",
    "        #test_fuzzy_metrics[i][evaluation_metrics.PRECISION],\n",
    "        #test_fuzzy_metrics[i][evaluation_metrics.FSCORE],\n",
    "    ]\n",
    "\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\nAverages\")\n",
    "\n",
    "results_means_df = results_df.mean()\n",
    "results_std_df = results_df.std()\n",
    "display(results_means_df)\n",
    "\n",
    "print(\"\\STD\")\n",
    "display(results_std_df)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save notebook so all output is archived by the next cell\n",
    "\n",
    "from IPython.display import Javascript\n",
    "script = '''\n",
    "require([\"base/js/namespace\"],function(Jupyter) {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "});\n",
    "'''\n",
    "Javascript(script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export HTML copy of this notebook\n",
    "\n",
    "notebook_file_name =  \"/Users/Josh Ehrlich/Courses/CISC881/Project/data/\"+this_notebook_name + \"_\" + save_timestamp + \".html\"\n",
    "notebook_fullname = os.path.join(notebooks_save_fullpath, notebook_file_name)\n",
    "\n",
    "os.system(\"jupyter nbconvert --to html \" + this_notebook_name + \" --output \" + notebook_fullname)\n",
    "print(\"Notebook saved to: {}\".format(notebook_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Notebook_name\", this_notebook_name)\n",
    "print(\"fullname\", notebook_fullname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
